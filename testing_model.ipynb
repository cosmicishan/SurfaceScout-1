{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import ViTConfig, ViTModel\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 73031\n",
      "Unique labels: 8\n",
      "Training set size: 51121\n",
      "Validation set size: 10955\n",
      "Test set size: 10955\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/ishan/Projects/Flask/Dataset\"\n",
    "\n",
    "filepath_list, feature_list = [], []\n",
    "\n",
    "with open(os.path.join(data_dir, \"labels-map-proj-v3.txt\")) as f:\n",
    "    lines = f.readlines()\n",
    "    for each_line in lines:\n",
    "        line_list = each_line.split(\" \")\n",
    "        filepath_list.append(os.path.join(data_dir, \"map-proj-v3\", line_list[0]))\n",
    "        feature_list.append(int(line_list[1]))\n",
    "\n",
    "data_dict = {\"filepath\": filepath_list, \"label\": feature_list}\n",
    "data_df = pd.DataFrame(data_dict)\n",
    "\n",
    "data_df = data_df[~data_df[\"filepath\"].str.contains(\".DS_Store\")]\n",
    "\n",
    "print(f\"Number of samples: {len(data_df)}\")\n",
    "print(f\"Unique labels: {data_df['label'].nunique()}\")\n",
    "\n",
    "data_df = data_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    data_df,\n",
    "    test_size=0.3,\n",
    "    stratify=data_df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self, data_df):\n",
    "\n",
    "    self.images = []\n",
    "    self.labels = []\n",
    "    self.transform = transforms.ToTensor()\n",
    "\n",
    "    for _, row in data_df.iterrows():\n",
    "      image_path = row[\"filepath\"]\n",
    "      self.images.append(image_path)\n",
    "      self.labels.append(row[\"label\"])\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      image_path = self.images[idx]\n",
    "      label = self.labels[idx]\n",
    "      filename = image_path.split(\"/\")[-1]\n",
    "\n",
    "      if not os.path.exists(image_path):\n",
    "         print(image_path)\n",
    "      image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "      image = np.stack((image,)*3, axis=-1)\n",
    "\n",
    "      return image, label, filename.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 1\n",
    "learning_rate = 2e-5\n",
    "\n",
    "train_dataset = CustomDataset(train_df)\n",
    "val_dataset = CustomDataset(val_df)\n",
    "test_dataset = CustomDataset(test_df)\n",
    "\n",
    "n_cpu = os.cpu_count()\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=n_cpu, drop_last=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=n_cpu, drop_last=True)\n",
    "test_dl =  DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params (M): 127.50\n"
     ]
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, config, num_labels):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "        self.vit = ViTModel(config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.vit.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        outputs = self.vit(inputs)\n",
    "        output = self.dropout(outputs.last_hidden_state[:, 0])\n",
    "        logits = self.classifier(output)\n",
    "        logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Define Models\n",
    "config = ViTConfig(\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    num_classes=8,\n",
    "    num_channels=1,\n",
    "    embed_dim=1024,\n",
    "    depth=24,\n",
    "    num_heads=16,\n",
    "    mlp_ratio=4,\n",
    "    num_attention_heads=16,\n",
    "    hidden_size=1024,\n",
    "    num_layers=24\n",
    ")\n",
    "\n",
    "model = Classifier(config, 8).to(device)\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Number of params (M): %.2f' % (n_parameters / 1.e6))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTForImageClassification(nn.Module):\n",
    "\n",
    "    def __init__(self, num_labels=3):\n",
    "\n",
    "        super(ViTForImageClassification, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-large-patch16-224-in21k')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.vit.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "\n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        output = self.dropout(outputs.last_hidden_state[:, 0])\n",
    "        logits = self.classifier(output)\n",
    "        logits = torch.nn.functional.softmax(logits, dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),         \n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  \n",
    "])\n",
    "\n",
    "ground_truth, prediction = [] ,[]\n",
    "\n",
    "model = torch.load(\"vit_imagenet_hirise_high.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for input, target in zip(test_df['filepath'], test_df['label']):\n",
    "\n",
    "        image = Image.open(input).convert('RGB')\n",
    "\n",
    "        input_tensor = transform(image).unsqueeze(0)  \n",
    "\n",
    "        output = model(input_tensor)\n",
    "\n",
    "        label = output.cpu().detach().numpy()\n",
    "        prediction.append(np.argmax(label))\n",
    "        ground_truth.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8311571364250337\n",
      "Precision: 0.6908221854302622\n",
      "Recall: 0.8311571364250337\n",
      "F1-Score: 0.7545198297716315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishan/anaconda3/envs/computervision/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(ground_truth, prediction))\n",
    "print(\"Precision:\", precision_score(ground_truth, prediction, average=\"weighted\"))\n",
    "print(\"Recall:\", recall_score(ground_truth, prediction, average=\"weighted\"))\n",
    "print(\"F1-Score:\", f1_score(ground_truth, prediction, average=\"weighted\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
